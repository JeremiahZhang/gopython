{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "D:\\ProgramData\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:26: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(12, activation=\"relu\", kernel_initializer=\"uniform\", input_dim=8)`\n",
      "D:\\ProgramData\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:27: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(8, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "D:\\ProgramData\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:28: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"sigmoid\", kernel_initializer=\"uniform\")`\n",
      "D:\\ProgramData\\Anaconda2\\lib\\site-packages\\keras\\models.py:844: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 32/768 [>.............................] - ETA: 0sacc: 78.39%\n",
      "Save model to disk\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# MLP for json, hdf5\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense\n",
    "from keras.models import model_from_json\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import urllib\n",
    "\n",
    "url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data\"\n",
    "raw_data = urllib.urlopen(url)\n",
    "dataset = np.loadtxt(raw_data, delimiter=\",\")\n",
    "\n",
    "X = dataset[:, 0:8]\n",
    "y = dataset[:, 8]\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, init='uniform', activation='relu')) \n",
    "model.add(Dense(8, init='uniform', activation='relu')) \n",
    "model.add(Dense(1, init='uniform', activation='sigmoid')) \n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X, y, nb_epoch=150, batch_size=10, verbose=0)\n",
    "\n",
    "# Evaluate the model\n",
    "scores = model.evaluate(X, y)\n",
    "print(\"{0}: {1:.2f}%\".format(model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "# Here is the Point\n",
    "# save model: JSON\n",
    "model_json = model.to_json()\n",
    "with open('model.json', 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "# save weights: HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Save model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk, OK\n",
      "acc: 78.39%\n"
     ]
    }
   ],
   "source": [
    "# later when you want to use the model\n",
    "# load json and creat model\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "# load weight into new model\n",
    "loaded_model.load_weights('model.h5')\n",
    "print(\"Loaded model from disk, OK\")\n",
    "\n",
    "# Evaluate loaded model on test data\n",
    "loaded_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "score = loaded_model.evaluate(X, y, verbose=0)\n",
    "\n",
    "print(\"{0}: {1:.2f}%\".format(loaded_model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save model to disk\n",
      "loaded model from disk\n",
      "acc: 78.39%\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_yaml\n",
    "\n",
    "# save model to YAML\n",
    "model_yaml = model.to_yaml()\n",
    "\n",
    "with open('model.yaml', 'w') as yaml_file:\n",
    "    yaml_file.write(model_yaml)\n",
    "\n",
    "# save weights to hdf5\n",
    "model.save_weights('model1.h5')\n",
    "print(\"Save model to disk\")\n",
    "\n",
    "# later...\n",
    "# Load YAML to create model\n",
    "yaml_file = open('model.yaml', 'r')\n",
    "loaded_model_yaml = yaml_file.read()\n",
    "yaml_file.close()\n",
    "\n",
    "loaded_model = model_from_yaml(loaded_model_yaml)\n",
    "\n",
    "# load weights\n",
    "loaded_model.load_weights('model1.h5')\n",
    "print(\"loaded model from disk\")\n",
    "\n",
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "score = loaded_model.evaluate(X, y, verbose=0)\n",
    "\n",
    "print(\"{0}: {1:.2f}%\".format(loaded_model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

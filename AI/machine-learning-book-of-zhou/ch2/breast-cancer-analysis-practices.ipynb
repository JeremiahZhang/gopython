{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome\n",
    "Hi Members of Watermelon Biting Group! We will use this data set for Chapter 2 of Zhou's Machine Learning textbook. You are welcomed to fork this notebook and make your own."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-processing\n",
    "Before we get started, there is some pre-processing work to be done. You can just run the code blocks below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# Any results you write to the current directory are saved as output.\n",
    "\n",
    "# Read the input file and put the data to pandas' dataframe format.\n",
    "# df = pd.read_csv(\"../input/data.csv\")\n",
    "df = pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop('id', axis=1, inplace=True)\n",
    "df.drop('Unnamed: 32', axis=1, inplace=True)\n",
    "df['diagnosis'].replace({'M':1,'B':0},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have removed the features that are not useful to us, and transformed the \"M\" \"B\" labels to \"1\" and \"0\" values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Data type for each Attribute\n",
    "types = df.dtypes\n",
    "print(types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "description = df.describe()\n",
    "print(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Class distribution there are 357 are begin, and 212 are malignant\n",
    "class_counts = df.groupby('diagnosis').size()\n",
    "print(class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Correlations Between Attributes\n",
    "pd.set_option('display.width', 100)\n",
    "pd.set_option('precision', 3)\n",
    "corrections = df.corr(method='pearson')\n",
    "print(corrections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skew of Univariate Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "skew = df.skew()\n",
    "print(skew)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization\n",
    "## Univariate Plots\n",
    "### 1 Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get dataframe column name\n",
    "features = list(df) \n",
    "n_feature = df.shape[1]\n",
    "\n",
    "for idx in range(1, n_feature):\n",
    "    df.iloc[:, idx].hist()\n",
    "    plt.title(features[idx])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Density plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for idx in range(1, n_feature):\n",
    "    df.iloc[:, idx].plot(kind='density')\n",
    "    plt.title(features[idx])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Box and Whisker Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for idx in range(1, n_feature):\n",
    "    df.iloc[:, idx].plot(kind='box')\n",
    "    plt.title(features[idx])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate Plots\n",
    "### Correlation Matrix Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "correlations = df.corr()\n",
    "\n",
    "plt.rcParams['font.size'] = 40\n",
    "\n",
    "fig = plt.figure(figsize=(31, 31))\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(correlations, vmin=-1, vmax=1)\n",
    "fig.colorbar(cax)\n",
    "ticks = np.arange(0, 31,1)\n",
    "\n",
    "ax.set_xticks(ticks)\n",
    "ax.set_yticks(ticks)\n",
    "ax.set_xticklabels(features, rotation=90)\n",
    "ax.set_yticklabels(features)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# More generic correlation matrix plot\n",
    "\n",
    "fig = plt.figure(figsize=(32,32))\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(correlations, vmin=-1, vmax=1)\n",
    "fig.colorbar(cax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Scatter plot matrix\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [50.0, 50.0]\n",
    "\n",
    "scatter_matrix(df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare your data \n",
    "\n",
    "- Rescale data\n",
    "- Standardize data\n",
    "- Normalize data\n",
    "- Binarize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Rescale data (between 0 and 1)\n",
    "\n",
    "from numpy import set_printoptions\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "array = df.values\n",
    "\n",
    "# Separate array into input and output components\n",
    "X = array[:, 1:31]\n",
    "Y = array[:, 0] # Diagnosis is the output feature class\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "rescaledX = scaler.fit_transform(X)\n",
    "\n",
    "# Summarize transformed data\n",
    "set_printoptions(precision=3)\n",
    "print(rescaledX[0:5, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Standardize Data\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler_std = StandardScaler().fit(X) \n",
    "rescalerX_std = scaler_std.transform(X)\n",
    "\n",
    "# Summarize transformed data\n",
    "set_printoptions(precision=3)\n",
    "print(rescalerX_std[0:5, 0:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Normalize Data\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "scaler_norm = Normalizer().fit(X)\n",
    "normalizedX = scaler_norm.transform(X)\n",
    "\n",
    "# Summarize transformd data\n",
    "set_printoptions(precision=7)\n",
    "print(normalizedX[0:5, 0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Binarize Data\n",
    "\n",
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "binarizer = Binarizer(threshold=0.0).fit(X)\n",
    "binaryX = binarizer.transform(X)\n",
    "\n",
    "# summarize transformed data\n",
    "set_printoptions(precision=3)\n",
    "print(binaryX[0:10, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Univariate selection\n",
    "# Feature extraction with Univariate statistical test (Chi-squared for classfication)\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "# feature extraction \n",
    "test = SelectKBest(score_func=chi2, k=8)\n",
    "fit = test.fit(X, Y)\n",
    "\n",
    "# summarize scores\n",
    "set_printoptions(precision=4)\n",
    "print(fit.scores_)\n",
    "features_selected = fit.transform(X)\n",
    "\n",
    "# summarize selected features\n",
    "print(features_selected[0:5, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Recursive Feature Elimination\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# feature extraction\n",
    "model = LogisticRegression()\n",
    "rfe = RFE(model, 3) # Top 3 features\n",
    "fit = rfe.fit(X, Y)\n",
    "\n",
    "print(\"Num Features: %d\") % fit.n_features_\n",
    "print(\"Selected Features: %s\") % fit.support_\n",
    "print(\"Feature Ranking: %s\") % fit.ranking_\n",
    "\n",
    "features_rfe = fit.transform(X)\n",
    "print(features_rfe[0:5, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Principal Component Analysis\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# feature extraction\n",
    "pca = PCA(n_components=3)\n",
    "fit = pca.fit(X)\n",
    "\n",
    "# summarize components\n",
    "print(\"Explained Variance: %s\") % fit.explained_variance_ratio_\n",
    "print(fit.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Feature Importance  \n",
    "# With Extra Trees Classifier\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "# feature extraction\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(X, Y)\n",
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the Performance of ML Algorithm with Resampling\n",
    "\n",
    "0. The best way to evaluate the performance of an algorithm would be to make predictions for new data to which you already know the answer.\n",
    "\n",
    "1. Use clever techniques from statistics called resampling methods that allow you to make accurate estimates for how well your algorithm will perform on new data.\n",
    "\n",
    "## Five different techniques \n",
    "\n",
    "We can use to split up our training dataset and create useful estimates of performance fo r our machine learning algorithm\n",
    "\n",
    "- Hold-out: Train and test sets\n",
    "- K-fold cross validation\n",
    "- Leave one out cross validation\n",
    "- Repeated random test-train splits\n",
    "- Bootstrapping: (in sklearn \"The deprecated Bootstrap cross-validation iterator was removed.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Method 1: hold-out Split into train and test sets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "test_size = 0.33\n",
    "seed = 42\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, \n",
    "                                                    random_state=seed)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "result = model.score(X_test, Y_test)\n",
    "\n",
    "print(\"Accuracy: {0:.3f}%\".format(result*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Method 2: K-fold Cross-validation\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "num_folds = 10\n",
    "seed = 42\n",
    "kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "\n",
    "model = LogisticRegression()\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "\n",
    "print(\"Accuracy:{0:.3f}%(std: {1:.3f}%)\".format(results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Method 3: Leave One Out Cross Validation\n",
    "\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "num_folds = 10\n",
    "loocv = LeaveOneOut()\n",
    "model = LogisticRegression()\n",
    "results_loocv = cross_val_score(model, X, Y, cv=loocv)\n",
    "\n",
    "print(\"Accuracy: {0:.3f}% (std: {1:.3f}%)\".format(results_loocv.mean()*100.0, \n",
    "                                                 results_loocv.std()*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Method 4: Ramdom repeated subsampling\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "n_splits = 10\n",
    "test_size = 0.33\n",
    "seed = 42\n",
    "kfold = ShuffleSplit(n_splits=n_splits, test_size=test_size, random_state=seed)\n",
    "\n",
    "model = LogisticRegression()\n",
    "results_shuffle = cross_val_score(model, X, Y, cv=kfold)\n",
    "\n",
    "print(\"Accuracy:{0:.3f}%(std:{1:.3f}%)\".format(results_shuffle.mean()*100.0, \n",
    "                                              results_shuffle.std()*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Method 5: Bootstrapping\n",
    "\n",
    "# from sklearn import cross_validation\n",
    "\n",
    "# n_samples = df.shape[0]*(df.shape[1]-1)\n",
    "# n_bootstraps = 10\n",
    "# n_train = 0.66\n",
    "# n_test = 0.33\n",
    "# seed = 42\n",
    "\n",
    "# bs = cross_validation.Bootstrap(n_samples, n_bootstraps=n_bootstraps, n_train=n_train, n_test=n_test,\n",
    "#               random_state=seed)\n",
    "\n",
    "# model = LogisticRegression()\n",
    "# results_bs = cross_val_score(model, X, Y, cv=bs)\n",
    "\n",
    "# print(\"Accuracy:{0:.3f}%(std:{1:.3f}%)\".format(results_bs.mean()*100.0, \n",
    "#                                               results_bs.std()*100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Algorithm Performance Metrics\n",
    "\n",
    "- Classification Accuracy\n",
    "- Logarithmic Loss\n",
    "- Area Under ROC Curve: AUC\n",
    "- Confusion Matrix\n",
    "- Classification Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following code to get train/test data sets, generate a classifier and to make predictions, so that the results can be used to practice different performance measures. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Classification Accuracy\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "kfold = KFold(n_splits=10, random_state=42)\n",
    "model = LogisticRegression()\n",
    "\n",
    "scoring = 'accuracy'\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "\n",
    "print(\"Accuracy:{0:.3f}%(std: {1:.3f}%)\".format(results.mean()*100.0, \n",
    "                                                results.std()*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Logarithmic Loss\n",
    "\n",
    "# Log Loss quantifies the accuracy of a classifier by penalising false classifications. \n",
    "# Minimising the Log Loss is basically equivalent to maximising the accuracy of the \n",
    "# classifier, but there is a subtle twist.\n",
    "\n",
    "# Smaller logloss is better with 0 representing a perfect logloss.\n",
    "\n",
    "scoring = 'neg_log_loss'\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "\n",
    "print(\"Logloss: {0:.3f}(std:{1:.3f})\".format(results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ROC curve\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33,\n",
    "                                                   random_state=42)\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "y_score = model.fit(X_train, y_train).decision_function(X_test)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_score)\n",
    "\n",
    "Logistic_Reg_auc = roc_auc_score(y_test, y_score)\n",
    "\n",
    "print(\"AUC of LogisticRegression using hold-out method: {0:.3f}\".format(Logistic_Reg_auc))\n",
    "\n",
    "# PLOT roc curve\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         label='ROC curve (area = {:.3f})'.format(Logistic_Reg_auc))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# AUC \n",
    "\n",
    "results = cross_val_score(model, X, Y, cv=kfold, scoring='roc_auc')\n",
    "print(\"AUC: {0:.3f}({1:.3f})\".format(results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Cross Validation Classification Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "predicted = model.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "matrix = confusion_matrix(y_test, predicted)\n",
    "\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Classification Report\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(y_test, predicted)\n",
    "\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises of Chapter 1\n",
    "\n",
    "## P4 ex1.1\n",
    "\n",
    "1. Medical diagnosis:\n",
    "  - 输入空间X：病人的症状。\n",
    "  - 输出空间Y：病人得了啥病\n",
    "2. Handwritten digit recognition\n",
    "  - 输入空间X：邮政编码的数字图片 pixel\n",
    "  - 输出空间Y：数字（到底是什么数字）\n",
    "3. Determining if an email is spam or not\n",
    "  - 输入空间X：邮件（内容）\n",
    "  - 输出空间Y：是垃圾邮件还是非垃圾邮件\n",
    "4. Predicting how an electric load varies with price, temperature, and day of the week\n",
    "  - 输入空间X：price, tepmerature, and day of the week\n",
    "  - 输出空间Y：electric load\n",
    "5. A problem of interest to you fr which there is no analytic solution, but you have data from which to construct an empirical solution.\n",
    "  - X：data of problem\n",
    "  - Y：solution\n",
    "\n",
    "## P6 ex1.2\n",
    "\n",
    "a. 广告，购物，情色，发票，商店，打折，影片...\n",
    "b. 亲人，学习，...\n",
    "c. Threshold or b\n",
    "\n",
    "## P7 ex1.3\n",
    "\n",
    "a. 如果x(t)被错分，实际的y(t)和$$\\vec w^T(t)\\vec x(t)$$异号，即$$y(t)\\vec w^T(t)\\vec x(t) < 0$$，要不然就分类正确。\n",
    "b. $$\\begin{align}\n",
    "y(t) \\vec w^T(t+1) \\vec x(t) &= y(t)[\\vec w^T(t)+y(t)\\vec x(t)] \\vec x(t) \\\\\n",
    "&= y(t)\\vec w^T(t) \\vec x(t) + y^2(t) \\vec x^T(t) \\vec x(t) \\\\\n",
    "& >  y(t)\\vec w^T(t) \\vec x(t)\n",
    "\\end{align}$$ （第二项大于0）\n",
    "c. 从a和b可以看出，如果x(t)被错分，则会修正权重$$\\vec w(t+1) = \\vec w(t) + y(t)\\vec x(t) $$, $$y(t)\\vec w^T(t) \\vec x(t)$$从原来的 $$<0$$，慢慢会变成 $$>0$$. 最后 $$y \\vec w^T x > 0$$, x 被正确分类。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P8 ex1.4\n",
    "\n",
    "产生数据，使用python编程来尝试一些。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7c49da0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7b5a358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_1 = np.random.rand(10, 2)\n",
    "data_2 = np.random.rand(10, 2) + 1\n",
    "\n",
    "plt.scatter(data_1[:, 0], data_1[:,1], c='black')\n",
    "plt.scatter(data_2[:, 0], data_2[:,1], c='yellow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(data_1)\n",
    "df2 = pd.DataFrame(data_2)\n",
    "df = df.append(df2, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def creat_label():\n",
    "    label = []\n",
    "    for i in range(0,20):\n",
    "        if i < 10:\n",
    "            label.append(-1)\n",
    "        else:\n",
    "            label.append(1)\n",
    "    return label\n",
    "\n",
    "label = creat_label()\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0\n",
       "0  -1\n",
       "1  -1\n",
       "2  -1\n",
       "3  -1\n",
       "4  -1\n",
       "5  -1\n",
       "6  -1\n",
       "7  -1\n",
       "8  -1\n",
       "9  -1\n",
       "10  1\n",
       "11  1\n",
       "12  1\n",
       "13  1\n",
       "14  1\n",
       "15  1\n",
       "16  1\n",
       "17  1\n",
       "18  1\n",
       "19  1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array(label)\n",
    "\n",
    "type(a)\n",
    "df2 = pd.DataFrame(a)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['label'] = df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.990524</td>\n",
       "      <td>0.054373</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.620654</td>\n",
       "      <td>0.887699</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.853485</td>\n",
       "      <td>0.714406</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.807625</td>\n",
       "      <td>0.116543</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.532413</td>\n",
       "      <td>0.084450</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.749864</td>\n",
       "      <td>0.874287</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.346916</td>\n",
       "      <td>0.035263</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.943622</td>\n",
       "      <td>0.455440</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.456648</td>\n",
       "      <td>0.705626</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.858830</td>\n",
       "      <td>0.104357</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.027952</td>\n",
       "      <td>1.800024</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.270633</td>\n",
       "      <td>1.471578</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.424227</td>\n",
       "      <td>1.386003</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.520125</td>\n",
       "      <td>1.656834</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.700074</td>\n",
       "      <td>1.834281</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.557214</td>\n",
       "      <td>1.587775</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.080090</td>\n",
       "      <td>1.678737</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.939142</td>\n",
       "      <td>1.659189</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.748488</td>\n",
       "      <td>1.143980</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.551583</td>\n",
       "      <td>1.502621</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1  label\n",
       "0   0.990524  0.054373     -1\n",
       "1   0.620654  0.887699     -1\n",
       "2   0.853485  0.714406     -1\n",
       "3   0.807625  0.116543     -1\n",
       "4   0.532413  0.084450     -1\n",
       "5   0.749864  0.874287     -1\n",
       "6   0.346916  0.035263     -1\n",
       "7   0.943622  0.455440     -1\n",
       "8   0.456648  0.705626     -1\n",
       "9   0.858830  0.104357     -1\n",
       "10  1.027952  1.800024      1\n",
       "11  1.270633  1.471578      1\n",
       "12  1.424227  1.386003      1\n",
       "13  1.520125  1.656834      1\n",
       "14  1.700074  1.834281      1\n",
       "15  1.557214  1.587775      1\n",
       "16  1.080090  1.678737      1\n",
       "17  1.939142  1.659189      1\n",
       "18  1.748488  1.143980      1\n",
       "19  1.551583  1.502621      1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = df.values\n",
    "\n",
    "X = dataset[:, 0:2].astype(float)\n",
    "Y = dataset[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20L, 2L)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction[-1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.]\n",
      "Actual[-1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.]\n",
      "Accuracy100.0%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "# random \n",
    "seed = 42\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create model\n",
    "pla = Perceptron(n_iter=50, verbose=0, random_state=seed, fit_intercept=True, eta0=0.002)\n",
    "pla.fit(X, Y)\n",
    "\n",
    "# print results\n",
    "print('Prediction' + str(pla.predict(X)))\n",
    "print('Actual' + str(Y))\n",
    "print('Accuracy' + str(pla.score(X, Y)*100) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coef 0(w_1):0.00138497280103\n",
      "Coef 1(w_2):0.0040246437505\n",
      "Bias[-0.006]\n"
     ]
    }
   ],
   "source": [
    "# output the values\n",
    "print \"Coef 0(w_1):\" + str(pla.coef_[0,0]) \n",
    "print \"Coef 1(w_2):\" + str(pla.coef_[0,1])\n",
    "print \"Bias\" + str(pla.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0xc624a20>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAFwRJREFUeJzt3X9sHOed3/H3R7JshLFhnyPaZ1jmrtuoaXWurFJbXZAI\njdUiqWw0EALkD7mLBAhyWPhaF9f+cTj3CNhADwRaBCiKa5UzCFdwDt7YKBo7UVH/OAdtT8m5vhMp\nK/4ZOYpCUmICS5ETpw4PMHT69o8d0iuK1A7J3Z3hPp8XsODOMzPLL1ejzz7z7PxQRGBmZunYVHQB\nZmbWXw5+M7PEOPjNzBLj4DczS4yD38wsMQ5+M7PEOPjNzBLj4DczS4yD38wsMdcUXcBytm7dGtVq\ntegyzMw2jKmpqZ9HxHCeZUsZ/NVqlcnJyaLLMDPbMCTN5F3WQz1mZolx8JuZJcbBb2aWGAe/mVli\nHPxmZolx8JuZJcbBb2aWGAe/mQ2QJlClFW3VbNqWKuUJXGZmq9cEGsB8Nj2TTQPUC6morNzjN7MB\nMcaHob9gPmu3dg5+GzDe1U/X7Crb0+XgtwGysKs/AwQf7uo7/NMwssr2dDn4bYB4Vz9t48DQkrah\nrN3aOfhtgHhXP211YAKoAMp+TuAvdq/ko3psgIzQGt5Zrt3SUMdB31nHHr+kw5LOSXp9hfm/L+lE\n9nhd0t9IujmbNy3ptWyeL7BvPeZdfbM88gz1PA7sX2lmRHwtInZFxC7g3wJ/HhHvti2yL5tfW1+p\nZp14V98sj45DPRFxVFI15+vdDzy5noLM1se7+maddO3LXUlDtPYMvtXWHMB3JU1Jaiy/ppmZ9VM3\nv9z9PPAXS4Z59kbEnKRbgBcl/TAiji63cvbB0AAYGfGXcWZmvdLNwzkPsmSYJyLmsp/ngGeAPSut\nHBETEVGLiNrwcK4bxZuZ2Rp0Jfgl3Qh8BvhOW9tHJd2w8Bz4HLDskUFmZtY/HYd6JD0J3ANslXQW\neATYAhARj2aLfQH4s4j4dduqtwLPSFr4Pd+MiOe7V7qZma1FnqN67s+xzOO0DvtsbzsN3L3WwszM\nrDd8yQZLlK/iaenyJRssQb5hh6XNPX5LkK/i2X3eg1q7/r937vFbgnwVz+7yHtTaFfPeucdvCfIN\nO7rLe1BrV8x75+C3BPkqnt3lPai1K+a9c/BbgnwVz+7yHtTaFfPeOfgtUXVgGriU/XTor533oNau\nmPfOwW9m6+Q9qLUr5r1z8JtZF1xtD8qHel5d//c+fTinmfWQD/UsI/f4zayHfKhnGTn4zayHfKhn\nGTn4zayHfKhnGTn4zayHfKhnGTn4zayHfKhnGfmoHjPrsToO+nJxj9/MLDEdg1/SYUnnJC17o3RJ\n90h6T9KJ7PFw27z9kk5KOiXpoW4WbmZma5Onx/84sL/DMt+LiF3Z498BSNoMHALuBXYA90vasZ5i\nzWyj8Vm7ZdQx+CPiKPDuGl57D3AqIk5HxAfAU8CBNbyOmW1IC2ftzgDBh2ftOvyL1q0x/k9JelXS\nc5J+K2u7HTjTtszZrM3MkuCzdsuqG8F/HBiJiJ3Afwa+vZYXkdSQNClp8vz5810oy2wjGcQhEZ+1\nW1brDv6I+FVEvJ89fxbYImkrMAfc0bbotqxtpdeZiIhaRNSGh4fXW5bZBjKoQyI+a7es1h38kn5T\nkrLne7LXvAAcA7ZLulPStcBB4Mh6f5/Z4BnUIRGftVtWHU/gkvQkcA+wVdJZ4BFgC0BEPAp8Efhd\nSReBvwYORkQAFyU9CLwAbAYOR8QbPfkrzDa0QR0SWThpa4zW3zJCK/R9MlfR1MrocqnVajE5OVl0\nGWZ9UqU1vLNUhdaNOcw6kzQVEbU8y/rMXbPCeUjE+svBb1Y4X8jM+ssXaTMrBV/IzPrHPX4zs8Q4\n+M2SNYgnjVkeHuoxS9LCSWML5w8snDQGHnIafO7xmyVpUE8aszwc/GZJGtSTxiwPB79ZknwdnZQ5\n+M2S5JPGUubgN0uSTxpLmY/qMUuWTxpLlXv8ZmaJcfCbmSXGwW9mlhgHv5lZYhz8ZmaJcfCbmSWm\nY/BLOizpnKTXV5hfl/SqpNckvSTp7rZ501n7CUm+l6KZWQnk6fE/Duy/yvyfAJ+JiL8P/BGts0Da\n7YuIXXnvBWlmZr3V8QSuiDgqqXqV+S+1Tb4MbFt/WWZm1ivdHuP/KvBc23QA35U0JamxwjpmZtZH\nXbtkg6R9tIJ/b1vz3oiYk3QL8KKkH0bE0RXWb5DdCWJkxFcINDPrla70+CXtBB4DDkTEhYX2iJjL\nfp4DngH2rPQaETEREbWIqA0PD3ejLDMzW8a6g1/SCPA08KWIeLut/aOSblh4DnwOWPbIIDMz65+O\nQz2SngTuAbZKOgs8AmwBiIhHgYeBjwFflwRwMTuC51bgmaztGuCbEfF8D/4GMzNbhTxH9dzfYf7v\nAL+zTPtp4O4r1zAzsyL5zF0zs8Q4+M3MEuPgNzNLjIPfzBLTBKq04q+aTafF99w1s4Q0aZ0nOp9N\nz2TTkNL9hx38tqE99thjnDhxgtHRUXbv3s2OHTvYsmVL0WVZaY3xYegvmM/aHfxmG8LJkyf5xje+\nwaFDhwC47rrr2Llz5+IHwejoKHfddRfXXXddwZVaOcyusn0wKSKKruEKtVotJid9+X7L59KlS/zo\nRz/i+PHjTE1Ncfz4cY4fP857770HwJYtW7jrrrsYHR1d/EDYuXMnH/nIRwqu3PqvSmt4Z6kKMN3X\nSrpN0lTey987+G0gRQSnT59mamqKV155hampKaampnj33XcB2Lx5Mzt27Fj8MBgdHWXXrl1cf/31\nBVduvbV0jB9giNZtRDb2UI+D32wZEcGZM2cW9woWfr7zzjsASOITn/jE4hDR7t272bVrFzfeeGPB\nlVt3NWmN6c8CI8A4Gz30wcFvlltE8NOf/nRxeGjhA2Fubm5xmY9//OOLHwYLj5tvvrnAqs2u5OA3\nW6d33nnnig+DmZkPx4ar1eplXyCPjo5yyy23FFixpc7Bb9YDFy5cuOLD4Mc//vHi/G3btl32BfLu\n3bu57bbbCqzYUuLgN+uTX/7yl7zyyiuXfRi8/fbbRASf/vSn+f73v190iZaI1QS/j+M3W4ebbrqJ\nffv2sW/fvsW2999/nxMnTnDx4sUCKzNbmYPfrMuuv/569u7d23lBs4L4Im1mZolx8JuZJaZj8Es6\nLOmcpGVvlK6WP5Z0StKrkkbb5u2XdDKb91A3Czczs7XJ0+N/HNh/lfn3AtuzRwP4EwBJm4FD2fwd\nwP2SdqynWDMzW7+OwR8RR4F3r7LIAeBPo+Vl4CZJtwF7gFMRcToiPgCeypY1M7MCdWOM/3bgTNv0\n2axtpXYzMytQab7cldSQNClp8vz580WXY2Y2sLoR/HPAHW3T27K2ldqXFRETEVGLiNrw8HAXyjIz\ns+V0I/iPAF/Oju75JPBeRPwMOAZsl3SnpGuBg9myZmZWoI5n7kp6ErgH2CrpLPAIsAUgIh4FngXu\nA07RurvBV7J5FyU9CLwAbAYOR8QbPfgbzMxsFToGf0Tc32F+AP9yhXnP0vpgMDOzkijNl7tmZtYf\nDn4zs8Q4+M3MEuPgNzNLjIO/xJrNJtVqlU2bNlGtVmk2m0WXZGYDwDdiKalms0mj0WB+fh6AmZkZ\nGo0GAPV6vcjSzGyDc4+/pMbGxhZDf8H8/DxjY2Nd/T3eqzBLj3v8JTU7O7uq9rXwXoVZmtzjL6mR\nkZFVta9Fv/YqzKxcHPwlNT4+ztDQ0GVtQ0NDjI+Pd+139GOvwszKx8FfUvV6nYmJCSqVCpKoVCpM\nTEx0dQimH3sVZlY+Dv4Sq9frTE9Pc+nSJaanp7s+7t6PvQozKx8Hf8L6sVdhZuWj1sU1y6VWq8Xk\n5GTRZZiZbRiSpiKilmdZ9/jNzBLj4DczS4yD38wsMQ5+M7PE5Ap+SfslnZR0StJDy8z/fUknssfr\nkv5G0s3ZvGlJr2Xz/I2tmVnB8txsfTNwCPgscBY4JulIRLy5sExEfA34Wrb854F/ExHvtr3Mvoj4\neVcrNzOzNcnT498DnIqI0xHxAfAUcOAqy98PPNmN4szMrPvyBP/twJm26bNZ2xUkDQH7gW+1NQfw\nXUlTkhprLdTMzLqj25dl/jzwF0uGefZGxJykW4AXJf0wIo4uXTH7UGiArxVjZtZLeXr8c8AdbdPb\nsrblHGTJME9EzGU/zwHP0Bo6ukJETERELSJqw8PDOcqysvFNXcw2hjzBfwzYLulOSdfSCvcjSxeS\ndCPwGeA7bW0flXTDwnPgc8Dr3Si8Xxxm+Szc1GVmZoaIWLypi98vs/LpGPwRcRF4EHgBeAv4bxHx\nhqQHJD3QtugXgD+LiF+3td0KfF/SD4C/Av5nRDzfvfJ7y2GWn2/qYrZx+CJtV1GtVpmZmbmivVKp\nMD093f+CSmzTpk0sty1J4tKlSwVUZJYWX6StS3yHqvx8UxezjcPBfxUOs/x8UxezjcPBfxUOs/x8\nUxezjcNj/B00m03GxsaYnZ1lZGSE8fFxh5mZlc5qxvgd/GZmA8Bf7pqZ2Yoc/GZmiXHwm5klxsFv\nZpYYB7+ZWWIc/GZmiXHwm5klxsFvZpYYB7+ZWWIc/GZmiXHwm5klxsFvZpYYB7+ZWWJyBb+k/ZJO\nSjol6aFl5t8j6T1JJ7LHw3nXNTOz/rqm0wKSNgOHgM8CZ4Fjko5ExJtLFv1eRPyzNa5rZmZ9kqfH\nvwc4FRGnI+ID4CngQM7XX8+6ZmbWA3mC/3bgTNv02axtqU9JelXSc5J+a5XrmplZn3Qc6snpODAS\nEe9Lug/4NrB9NS8gqQE0wDczNzPrpTw9/jngjrbpbVnbooj4VUS8nz1/FtgiaWueddteYyIiahFR\nGx4eXsWfYGZmq5En+I8B2yXdKela4CBwpH0BSb8pSdnzPdnrXsizrlm7ZrNJtVpl06ZNVKtVms1m\n0SWZDZyOQz0RcVHSg8ALwGbgcES8IemBbP6jwBeB35V0Efhr4GC07uK+7Lo9+ltsg2s2mzQaDebn\n5wGYmZmh0WgAUK/XiyzNbKColc/lUqvVYnJysugyrM+q1SozMzNXtFcqFaanp/tfkNkGImkqImp5\nlvWZu1Yas7Ozq2o3s7Vx8FtprHQ0l4/yMusuB7+Vxvj4OENDQ5e1DQ0NMT4+XlBFZoPJwW+lUa/X\nmZiYoFKpIIlKpcLExIS/2DXrMn+5a2Y2APzlrpmZrcjBb2aWGAe/mVliHPxmZolx8JuZJcbBb2aW\nGAe/mVliHPxmZolx8JuZJcbBb2aWGAe/mVliHPxmZolx8JuZJcbBb2aWmFzBL2m/pJOSTkl6aJn5\ndUmvSnpN0kuS7m6bN521n5Dkay2bmRXsmk4LSNoMHAI+C5wFjkk6EhFvti32E+AzEfELSfcCE8Bv\nt83fFxE/72LdZma2Rnl6/HuAUxFxOiI+AJ4CDrQvEBEvRcQvssmXgW3dLdPMzLolT/DfDpxpmz6b\nta3kq8BzbdMBfFfSlKTGSitJakialDR5/vz5HGWZmdladBzqWQ1J+2gF/9625r0RMSfpFuBFST+M\niKNL142ICVpDRNRqtfLdD9LMbEDk6fHPAXe0TW/L2i4jaSfwGHAgIi4stEfEXPbzHPAMraEjMzMr\nSJ7gPwZsl3SnpGuBg8CR9gUkjQBPA1+KiLfb2j8q6YaF58DngNe7VbyZma1ex6GeiLgo6UHgBWAz\ncDgi3pD0QDb/UeBh4GPA1yUBXMzu9n4r8EzWdg3wzYh4vid/iZmZ5aKI8g2n12q1mJz0If9mZnlJ\nmso63B35zF0zs8Q4+M3MEuPgNzNLjIPfzCwxDn4zs8Q4+M3MEuPgt9yazSbVapVNmzZRrVZpNptF\nl2Rma+Dgt1yazSaNRoOZmRkigpmZGRqNxhXh7w8Hs/LzCVyWS7VaZWZm5or2SqXC9PQ08OGHw/z8\n/OL8oaEhJiYmqNfr/SrVLEk+gaskBqn3Ozs727F9bGzsstAHmJ+fZ2xsrKe1mdnqOPh7JO/QyEYx\nMjLSsT3Ph4OZFc/B3yOD1vsdHx9naGjosrahoSHGx8cXp/N8OJhZ8Rz8PTJovd96vc7ExASVSgVJ\nVCqVK8bu83w4dMMgDaGZFSIiSvfYvXt3bHSVSiVo3XbyskelUim6tJ564oknolKphKSoVCrxxBNP\ndP31h4aGLntPh4aGuv57zDYaYDJyZuxA9fjL1BPsV++3bOr1OtPT01y6dInp6emuH80zaENoZkUY\nmOAv25epeYZGbPUGbQjNrAgDcxx/nuPMbePzv7PZ8pI8jt89wTSkOoRm1k25gl/SfkknJZ2S9NAy\n8yXpj7P5r0oazbtut/hQwjR4CM1s/ToGv6TNwCHgXmAHcL+kHUsWuxfYnj0awJ+sYt2ucE8wHb3+\nAtls0OXp8e8BTkXE6Yj4AHgKOLBkmQPAn2ZHFb0M3CTptpzrdoV7gmZm+VyTY5nbgTNt02eB386x\nzO051wVAUoPW3sKah2fq9bqD3sysg9J8uRsRExFRi4ja8PBw0eWYmQ2sPD3+OeCOtultWVueZbbk\nWNfMzPooT4//GLBd0p2SrgUOAkeWLHME+HJ2dM8ngfci4mc51zUzsz7q2OOPiIuSHgReADYDhyPi\nDUkPZPMfBZ4F7gNOAfPAV662bk/+EjMzy2Vgztw1M0tZkmfumplZPg5+M7PElHKoR9J54MorcfXG\nVuDnffpdeZWxJnBdq+W6Vsd15bdcTZWIyHUsfCmDv58kTeYdF+uXMtYErmu1XNfquK781luTh3rM\nzBLj4DczS4yDHyaKLmAZZawJXNdqua7VcV35raum5Mf4zcxS4x6/mVlikgj+vHcBk/QPJV2U9MWy\n1CXpHkknJL0h6c/LUJekGyX9D0k/yOr6Sh9qOizpnKTXV5i/4l3gCq6rntXzmqSXJN1dhrraluv3\nNt+xroK2+U7/jkVs83dI+t+S3sx+5+8ts8zatvuIGOgHrWsE/Rj4W8C1wA+AHSss979oXXfoi2Wo\nC7gJeBMYyaZvKUldfwj8h+z5MPAucG2P6/pHwCjw+grz7wOeAwR8EvjLPm1fner6FPAb2fN7y1JX\n279137b5nO9X37f5nHUVsc3fBoxmz28A3l7m/+KatvsUevx57wL2r4BvAedKVNc/B56OiFmAiOhH\nbXnqCuAGSQKup/Wf4GIvi4qIo9nvWclKd4HrqU51RcRLEfGLbPJlWpcm77kc7xf0f5vPU1cR23ye\nuorY5n8WEcez5/8PeIvWza3arWm7TyH4V7o72CJJtwNfILtXcFnqAv4O8BuS/o+kKUlfLkld/wX4\ne8BPgdeA34uIS32o7Wry1F20r9LqnRWuoG0+jyK2+TwK3eYlVYF/APzlkllr2u7z3IglBf8J+IOI\nuNT6QC+Na4DdwD8BPgL8X0kvR8TbxZbFPwVOAP8Y+NvAi5K+FxG/Kras8pK0j1bw7y26loy3+dUp\nbJuXdD2tPbN/3a3fl0Lw57mDWA14KvsPsBW4T9LFiPh2wXWdBS5ExK+BX0s6CtxNa6yvyLq+Avz7\naA0ynpL0E+DvAn/Vw7o6yVN3ISTtBB4D7o2IC0XXkylim8+jiG0+j0K2eUlbaIV+MyKeXmaRNW33\nKQz1dLwLWETcGRHViKgC/x34F334D5Dn7mTfAfZKukbSEK0b1b9VgrpmafXIkHQr8AngdI/r6mSl\nu8AVStII8DTwpRL0WhcVtM3nUcQ2n0fft/ns+4T/CrwVEf9xhcXWtN0PfI8/8t1BrJR1RcRbkp4H\nXgUuAY9FxFUPz+tHXcAfAY9Leo3W0QR/EBE9vXqhpCeBe4Ctks4Cj9C6p/NCTcveBa7XctT1MPAx\n4OtZ7/pi9OGCXznqKkSnuorY5vPURQHbPPBp4EvAa5JOZG1/CIy01bWm7d5n7pqZJSaFoR4zM2vj\n4DczS4yD38wsMQ5+M7PEOPjNzBLj4DczS4yD38wsMQ5+M7PE/H/qeogobXNYfgAAAABJRU5ErkJg\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc4eee80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot \n",
    "plt.scatter(data_1[:, 0], data_1[:,1], c='black')\n",
    "plt.scatter(data_2[:, 0], data_2[:,1], c='yellow')\n",
    "\n",
    "# Calc the hyperplane\n",
    "w = pla.coef_[0]\n",
    "a = -w[0] / w[1]\n",
    "w_0 = pla.intercept_[0]\n",
    "x = np.linspace(1, 1.2)\n",
    "y = a*x -(w_0) / w[1]\n",
    "\n",
    "# plot the line\n",
    "plt.plot(x, y, 'k-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## p17 ex1.7\n",
    "\n",
    "**The purpose of the exercise is to show what can possibly happen outside the data, namely anything, and it is the same no matter how you pick your g from the data.**\n",
    "\n",
    "a. 全是黑点和全是白点的H 与 g 总非训练样本上的差异。若H全是黑点，则与8个可能的g在非训练样本上预测的差别：H与g在三个点预测全错的g个数为1个，H与g在一个点上预测一样的g个数3个，H与g在两个点上预测一样的g个数为3个，H与g在三个点上预测一样的g的个数为1个。 全是白点一样的道理。（1-3-3-1）  \n",
    "b. 若选择匹配数据集最少的假设，则选择全是白点的，结果是和上面一样。  \n",
    "c. H是异或逻辑集。则H在未知样本上的预测f2一样。  \n",
    "d.  the learning a lgorith m picks the hypothesis that agrees with a l l training examples, but otherwise disagrees the most with the XOR. H包含所有可能的假设，而算法选择的是：在训练机集上，h(x)结果一样的假设，而在未知数据上的与XOR差别最大的假设。即f7，f7在训练集上预测为XOR逻辑，而在未知数据上，预测完全与XOR逻辑相反（差异最大）。  \n",
    "\n",
    "## p19 ex1.8:\n",
    "\n",
    "> If µ = 0.9, what is the probability that a sample of 1 marbles will h ave v <= 0.1? [Hints: 1. Use binomial distribution. 2. Te answer is a ver small number.]\n",
    "\n",
    "有放回的取10个弹球, 其中全是绿色球X=0和只有一个是红色球X=1的概率。X表示红色球数目。\n",
    "\n",
    "$$P(\\nu <= 0.1) = P(X=0) + P(X=1) = 0.1 ^ 10 + C_10^1 \\cdot 0.9 \\cdot 0.1^9 = 9.1 \\cdot 10^{-9}$$\n",
    "\n",
    "## P19 Exercise 1.9\n",
    "\n",
    "> If µ = 0 .9, use the Hoeffding I nequality to bound the probability that a sample of 10 marbles will have v <= 0.1 and compare the a nswer to the previous exercise.\n",
    "\n",
    "$$P(\\rvert \\nu - \\mu \\rvert ) > 0.8^{-}) \\leq 2e^{-2*0.8^2*10} = 5.5 * 10^{-6}$$\n",
    "\n",
    "## P23 ex1.10\n",
    "\n",
    "不理解如何进行试验，问题到底是什么意思\n",
    "\n",
    "## P25 ex1.11\n",
    "\n",
    "**训练集**：给定训练集D的样本数为25.\n",
    "\n",
    "**未知的目标函数** $$f: X \\rightarrow Y, \\ X = \\boldsymbol R, \\\\ Y=\\{-1, +1\\}$$\n",
    "\n",
    "**假设集**: 为了学习得到未知的目标函数f, 使用简单的假设集 $$H = \\{h_1, h_2\\}$$, 其中$$h_1=+1$$(任何训练样本输入进来，输出都为+1); $$h_2=-1$$(如何训练样本输入进来，输出都为-1).\n",
    "\n",
    "**学习算法**：S(smart) 和 C(cracy).\n",
    "\n",
    "- S 算法对于训练集中样本类别数多的就判别为该类别, 即如果训练集中类别为+1的样本数>类别为-1的样本数目, 则算法S将选择$$h_1$$假设作为g, 反之则选择$$h_2$$.\n",
    "- C 算法就是个“疯子”, 所做所谓与S相对,只要S选了$$h_1$$假设, 则C算法就故意选$$h_2$$假设作为g.\n",
    "\n",
    "**概率分布**: 我们要从确定性观点和概率的观点看看这些算法在训练样本上的性能. 从概率的角度来看:X上存在概率分布,其 $$P[f(x)=1] = p$$.\n",
    "\n",
    "> a) Can S produce a hypothesis that is guaranteed to perform better than random on any point outside D?\n",
    "\n",
    "NO. 无法保证. 极端例子, D中所有样本 yn=+1.\n",
    "\n",
    "> b) Assume for the rest of the exercise that all the examples in have Yn = 1. Is it possible that the hypothesis that C produces turns out to be better than the hypothesis that S produces?\n",
    "\n",
    "Yes. 算法S确定的假设为h1,而算法C确定的假设为h2. 那么在未知数据上, C的性能有可能比S的性能好.\n",
    "\n",
    "> c) If p = 0.9, what is the probability that S will produce a better hypothesis than C?\n",
    "\n",
    "p = 0.9 即 $$P(f(x)=+1) = 0.9$$, X 中有90%的概率能抽出类别为+1的样本,有10%的概率能抽出类别为-1的样本. 我们要求的是: $$P(P(h_S(x) = f(x)) > P(h_C(x) = f(x)))$$ 这个概率. x 为 outside D. 训练集以外的样本.$$h_S, h_C$$分别为算法C,D在训练集上训练得到的假设.\n",
    "\n",
    "现在我们已知的量有哪些呢?\n",
    "\n",
    "- D所有中所有样本 yn = +1.------> $$h_S = h_1, h_C = h_2$$.\n",
    "- 因为 $$P(f(x)=+1) = 0.9 \\rightarrow P(h_S(x) = f(x)) = 0.9$$\n",
    "- 因为 $$P(f(x)=-1) = 0.1 \\rightarrow P(h_C(x) = f(x)) = 0.1$$\n",
    "\n",
    "因为: 0.9 > 0.1 所以 $$P[P(h_S(x) = f(x)) > P(h_C(x) = f(x))] = 1$$\n",
    "\n",
    "> d)  Is there any value of p for which it is more likely than not that C will produce a better hypothesis than S?\n",
    "\n",
    "前提还是要记住: 所有训练样本的yn=+1. 仍延续 b, c的条件和结论\n",
    "\n",
    "问题是:  如果要 $$P(h_S(x) = f(x)) < P(h_C(x) = f(x))$$, 则p的取值如何.\n",
    "\n",
    "因为: $$P(h_S(x) = f(x)) = p, \\ P(h_C(x) = f(x)) = 1-p$$. 则 $$p < 1-p \\rightarrow p< 0.5$$\n",
    "\n",
    "> 练习总结:\n",
    "\n",
    "其实从这4个问题中,我们可以发现,对于a问题,我们不确定训练样本D中yn的情况,我们就无法确定算法S在训练集D上得到的假设在X上的性能就好于C算法的情况.\n",
    "\n",
    "但如果我们确定D中样本的情况,比如已知所有样本yn=+1, 则我们知道S和C算法得到的假设.\n",
    "\n",
    "进一步下去, 如果我们知道 outside D 以外的样本 X 的概率分布, 那么我们可以进一步确定, S算法和C算法得出假设在 X 上的性能情况.\n",
    "\n",
    "从中可以看出, 训练样本情况和X的概率分布情况, 在某种程度影响着算法的性能(在outside D上).\n",
    "\n",
    "## P26 ex1.12\n",
    "\n",
    "问题: learning problem, 目标函数 f 未知, 已知4000个数据. 我们要得到hypothesis g 来尽可能趋近 f. What is the best that you can promise her among the fllowing:\n",
    "\n",
    "> a. After learning you will provide her with a g that you will guarantee approximates well out of sample.\n",
    "\n",
    "> b. After learning you will provide her with a g, and with high probability\n",
    "the g which you produce will approximate well out of sample.\n",
    "\n",
    "> c.  One of two things wil l happen.\n",
    ">    - you will produce a hypothesis g\n",
    ">    - you will declare the you failed.\n",
    ">    if you do return a hypothesis g, then with high probability the g which you produce will approximate f well out of sample.\n",
    "\n",
    "a. 从ex1.11的练习中, 我们可以看出 a中 我们是无法保证的.\n",
    "b. 还是从练习1.1.中, 我们发现, 只要在知道这4000个数据集D的情况 以及 未知样本X的概率分布情况, 我们才能得到相关的概率.\n",
    "c. 综合来看, c答案可能是一个比较好的选项.(未知数据的不确定性.)\n",
    "\n",
    "或许,我们能给出的只有 Hoeffding Inequality.\n",
    "\n",
    "但是, 可不可以有这样的答案呢?\n",
    "\n",
    "> d. With high probability: you will either say you failed or you will produce a good g.\n",
    "\n",
    "## P31 EX1.13\n",
    "\n",
    "已知: h & target f, and $$P(h(x) \\neq f(x)) = \\mu, P(h(x)=f(x)) = 1 - \\mu$$, we use the same h to a pproximate a noisy version of f given by\n",
    "\n",
    "$$P(y|x) = \\begin{cases}\n",
    "\\lambda & y=f(x)\\\\\n",
    "1 - \\lambda & y \\neq f(x)\\end{cases}$$\n",
    "\n",
    "> a) what is the probability of error that h makes in approximating y if we use a noisy version of f.\n",
    "\n",
    "要求: $$P(h(x) \\neq y)$$\n",
    "\n",
    "- 第一种情况: $$h(x) = f(x), y \\neq f(x)$$, 其概率: $$P_1 = (1-\\mu)(1-\\lambda)$$;\n",
    "- 第二种情况: $$h(x) \\neq f(x), y = f(x)$$, 其概率: $$P_2 = \\mu \\lambda$$\n",
    "\n",
    "所以  $$P(h(x) \\neq y) = P_1 + P_2 = \\mu(2\\lambda -1) - \\lambda + 1$$\n",
    "\n",
    "> b) At what value of A will the perfrmance of h be independent of µ?\n",
    "\n",
    "也就是h的性能与u无关, 那么就是$$P(h(x) \\neq y)$$的值与u无关, 即u的系数为0, 则$$2\\lambda -1 = 0 \\rightarrow \\lambda = 0.5$$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prob 1.1 \n",
    "\n",
    "条件概率, 利用贝叶斯公式.  $$P(A, B) = P(A \\mid B)P(B) = P(B \\mid A) P(A)$$\n",
    "\n",
    "已知: \n",
    "    \n",
    "- 两个不透明的两个bag, bag1(两个黑球), bag2(1个黑球, 1个白球)\n",
    "- 第一次随机选择一个BAG, 取出来是黑球\n",
    "\n",
    "问: \n",
    "\n",
    "- 第二次在相同的BAG中取出黑球的概率是多少?\n",
    "\n",
    "答:\n",
    "\n",
    "1. 随机选择一个bag, 令变量bag1表示选择bag1, bag2表示选择bag2, 则$$P(bag1) = 0.5, P(bag2)=0.5$$;\n",
    "2. 令变量black表示取黑球事件, black1 表示取出第一次取出黑球, 则 $$P(black1) = P(bag1) + P(bag2)P(black|bag2)=0.5 + 0.5 \\cdot 0.5 = 0.75$$\n",
    "3. 现在要求第二次取出的是黑球(black2)的概率:P(black2|black1)\n",
    "\n",
    "$$P(black2|black1) = \\frac{P(black2, black1)}{P(black1)}$$\n",
    "\n",
    "(black2, black1) 第一次取出黑球, 第二次也取出黑球的事件 \n",
    "\n",
    "$$P(black2, black1) = P(bag1) * P(black) = 0.5 * 1 = 0.5$$\n",
    "\n",
    "所以, $$P(black2|black1)=\\frac{0.5}{0.75} = \\frac{2}{3}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prob 1.2 \n",
    "\n",
    "a) $$x_2 = a x_1 +b \\rightarrow 0 = 1b + ax_1 - x_2$$ \n",
    "\n",
    "then: $$w_0 =b, w_1 = a, w_2=-1$$ \n",
    "\n",
    "b) 在二维平面内画出:\n",
    "\n",
    "(1): $$1+2x_1 + 3x_2=0$$\n",
    "(2): $$-(1+2x_1+3x_2)=0$$\n",
    "\n",
    "两者划分正好相反"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prob 1.3\n",
    "\n",
    "已知: $${w^*}$$为PLA算法划分数据的一个权重集\n",
    "\n",
    "a) 证: $$\\rho = \\min_{1 \\leq n \\leq N} y_n({w^{*}}^T x_n) > 0$$, \n",
    "\n",
    "参考 exercise 1.3, $$x_n, y_n$$ 被正确划分, $${w^*}^T x_n$$的符号和$$y_n$$相同, 有 $$\\rho > 0$$\n",
    "\n",
    "b) 证: $$w^T(t) w^* \\geq w^T(t-1) w^* + \\rho$$ 并得出结论 $$w^T(t) w^* \\geq t \\rho$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{align}\n",
    "w^T(t)w^* &=(w(t-1)+y_n \\boldsymbol x_n)^T w^* \\\\\n",
    "          &= {w^*}^T (w(t-1)+y_n \\boldsymbol x_n)^T \\\\\n",
    "          &\\geq {w^*}^T w(t-1) + y_n {w^*}^T \\boldsymbol x_n \\\\\n",
    "          &\\geq {w^*}^T w(t-1) + \\rho\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "再一步步推演下去$$w^T(t-1)w^* \\geq {w^*}^T w(t-2) + \\rho$$\n",
    "\n",
    "可得到$$ w^T(t)w^* \\geq {w^*}^T w(t-t) + t\\rho$$\n",
    "\n",
    "又 $$w(0) = 0$$, 所以: $$ w^T(t)w^* \\geq t \\rho$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) because: $$w(t) = w(t-1) + y(t-1) x(t-1)$$, 等式左右两边都是向量, 向量的模等于向量的内积, 那么其模如下\n",
    " \n",
    " $$\\|y(t-1) \\| = 1, y(t-1) w(t-1)^T x(t-1) \\leq 0$$\n",
    " \n",
    "$$\\begin{align} \n",
    "\\|w(t)\\|^2 &= \\|w(t-1) + y(t-1)x(t-1)\\| ^2 \\\\\n",
    "           &= \\|w(t-1)\\|^2 +  2 y(t-1) w(t-1)^Tx(t-1) + \\|y(t-1)x(t-1)\\|^2 \\\\\n",
    "           &\\leq \\|w(t-1)\\|^2 + \\|x(t-1)\\|^2 \n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) 利用归纳法\n",
    "\n",
    "$$\\begin{align} \n",
    "\\|w(t)\\|^2 &\\leq \\|w(t-1)\\|^2 + \\|x(t-1)\\|^2  \\\\\n",
    "           &\\leq \\|w(t-2)\\|^2 + \\|x(t-2)\\|^2 + \\|x(t-1)\\|^2 \\\\\n",
    "           &\\leq \\|w(t-t)\\|^2 + \\|x(t-t)\\|^2 + \\cdots + \\|x(t-1)\\|^2 \\\\\n",
    "           &\\leq 0 + n \\cdot \\max\\|x\\|^2 \n",
    "\\end{align}$$\n",
    "\n",
    "其中 $$R = \\max_{1 \\leq n \\leq N} \\|x_n\\|$$\n",
    "\n",
    "则: $$\\|w(t)\\|^2 \\leq t R^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) 使用b和d的结论:\n",
    "\n",
    "$$ w^T(t)w^* \\geq t \\rho$$\n",
    "$$\\|w(t)\\|^2 \\leq t R^2$$\n",
    "\n",
    "有:\n",
    "\n",
    "$$ \\frac{w^T(t)}{\\|w(t)\\|}w^* \\geq \\frac{t\\rho}{\\sqrt{tR^2}} = \\sqrt{t} \\cdot \\frac{\\rho}{R}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因此, \n",
    "\n",
    "$$\\begin{align}\n",
    "t &\\leq \\frac{R^2}{\\rho ^2} \\frac{(w^T(t)w^*)^T (w^T(t)w^*)}{\\|w(t)\\|^2} \\\\\n",
    "   &\\leq \\frac{R^2}{\\rho ^2} \\cdot \\frac{(\\|w(t)\\| \\|w^*\\|)^2}{\\|w(t)\\|^2} = \\frac{R^2 \\|w^*\\|^2}{\\rho ^2}\n",
    "\\end{align}$$\n",
    "\n",
    "因:\n",
    "$$\\begin{align} \n",
    "\\frac{w^T(t)w^*}{\\|w(t)^T w^*\\|} = 1 &\\Rightarrow w^T(t)w^* = \\|w(t)^T w^*\\| \\\\\n",
    "    &\\Rightarrow w^T(t)w^* \\leq \\|w(t)^T\\| \\|w^*\\| \n",
    "\\end{align}$$\n",
    "\n",
    "$$\\frac{w^T(t)w^*}{\\|w(t)\\|\\|w^*\\|} \\leq 1 $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prob 1.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "python 编程实现, 暂且遗留. \n",
    "\n",
    "实现PLA的极简模式, 一步一步探究过程."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prob 1.5\n",
    "\n",
    "Like prob 1.4 coding later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prob 1.6\n",
    "\n",
    "red-green marble, out-of-sample, red marble$$ P(red \\ in \\ \\cal X) = \\mu=0.05, 0.5, 0.8$$, 计算下列情况下 in-sample 中red marble 的概率 $$\\nu$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a)** 只从整个输入空间中,取出一个sample, 其 不是red marble 的概率\n",
    "\n",
    "从总输入空间中去一个样本, 它不是red marble(是green marble)的概率: $$P=1-P(red \\ in \\cal X) = 1 - \\mu$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** 从整个输入空间中, 取出1000个样本samples, 计算其中至少有一个样本不是红色的概率, 也就是至少有一个样本为绿色的概率 P, 1-P = 事件(样本中的球都是红球)发生的概率\n",
    "\n",
    "$$P = 1 - \\mu^{1000}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c)** 若b的样本数目改为 1,000,000 呢?\n",
    "\n",
    "$$P = 1 - \\mu^{1,000,000}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Prob 1.7\n",
    "\n",
    "只有1个硬币时, 抛10次, 没有一个硬币出现 Head.\n",
    "\n",
    "a) 1个硬币抛N=10次,at least one coin will have $$\\nu=0$$ 也就是至少有一个硬币有head(事件A). 逆向思考: P(A) = 1 - P(B:没有一个硬币出现head).\n",
    "\n",
    "$$P(A) = 1 - P(B) = 1 - \\binom N 0 \\mu^0 (1-\\mu)^{N-0}$$\n",
    "\n",
    "那么对于1000个硬币, N=10 是什么意思呢? 是1000个硬币抛10次? 如果是这样, 每个硬币各抛10次, 1000个硬币各抛10次, P(A) = 1 - P(B). 现在关键是如何在这种情况下求P(B).\n",
    "\n",
    "- 一个硬币抛10次, 没有一个硬币出现head的概率为P(B)\n",
    "- 相当于, 这个操作重复1000次, 只不过是其他999个硬币, 但这有什么区别呢?没有啊\n",
    "- 那么继续下去, 这就是另外一个二项分布, P(B), 与1-P(B), n = 1000, 如果n中的某一个出现(1-P(B)), 那么就是出现有一个硬币有head.\n",
    "\n",
    "对于1个硬币, 抛10次, 没有出现head的概率为 $$ P(B) = \\binom {10} {0} \\mu^0 (1-\\mu)^{10-0}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "那么对于1000个硬币, 抛10次, 后 $$\\nu=0$$ 的概率为:\n",
    "\n",
    "$$1 - \\binom {1000} {1000} P(B)^{1000} (1-P(B))^0$$\n",
    "\n",
    "对于1,000,000个硬币和$$\\mu = 0.8$$类似"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于问题 B 的理解: (参考书籍论坛 [Stuck on Problem 1.7 - LFD Book Forum](http://book.caltech.edu/bookforum/showthread.php?t=4414))\n",
    "\n",
    "2个硬币, 各抛6次, 它们又是相互独立而抛(两个硬币出现head的概率$$\\mu=0.5$$).比如:\n",
    "\n",
    "- 实验1: 第一个硬币抛6次, 出现3次head, $$\\nu_1 = 0.5$$\n",
    "- 试验2: 第二个硬币抛6次, 出现2次head, $$\\nu_2 = \\frac{1}{3}$$\n",
    "\n",
    "因此: \n",
    "\n",
    "$$d_1 = \\mid \\nu_1 -\\mu_1 \\mid = 0, d_2 = \\mid \\nu_2 - \\mu_2 \\mid = \\frac{1}{6}$$\n",
    "\n",
    "$$d = \\max_I \\mid \\nu_i - \\mu_i \\mid = \\max(d_1, d_2) = \\frac{1}{6}$$\n",
    "\n",
    "我们要计算的是 $$P(d > \\epsilon)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$A = (|\\nu_1 - \\mu_1| > \\epsilon), B = (|\\nu_2 - \\mu_2| > \\epsilon)$$\n",
    "\n",
    "$$\\begin{align}\n",
    "P[max(\\nu_i - \\mu_i) > \\epsilon] \\leq P[A or B] &= P[A] + P[B] -P[A \\ and \\ B] \\\\\n",
    "&\\leq 2(2e^{-2\\epsilon^2 N}) - P[A \\ and \\ B] \\\\\n",
    "&\\leq 2(2e^{-2\\epsilon^2 N})\n",
    "\\end{align}$$\n",
    "\n",
    "概率计算参考: [顽想学概率一-2w-极简公理-条件概率 · Anifacc](https://anifacc.github.io/math/probability/2017/04/21/Axiom-Conditional-Probability/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prob 1.8\n",
    "\n",
    "a 马尔科夫不等式 参考 [切比雪夫不等式到底是个什么概念? - 知乎](https://www.zhihu.com/question/27821324)\n",
    "\n",
    "假如 t 为连续的随机变量, t > 0, 其概率密度函数PDF为f(t), 累积分布函数为 F(t)则\n",
    "\n",
    "$$\\begin{align} \n",
    "P(t \\geq a) &= F(\\infty) - F(a) \\\\\n",
    "        &= \\int_{0}^{\\infty} f(t)dt - \\int_{0}^{a}f(t)dt \\\\\n",
    "        &= \\int_{a}^{\\infty}f(t)dt\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "期望 \n",
    "\n",
    "$$\\begin{align} \n",
    "E(t) &= \\int_{0}^{\\infty}tf(t)dt \\\\\n",
    "    &= \\int_{0}^{a}tf(t)dt + \\int_{a}^{\\infty}tf(t)dt \\\\\n",
    "    &\\geq 0 + a\\int_{a}^{\\infty}f(t)dt \\\\\n",
    "    &\\geq aP(t\\geq a) \\\\\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so: $$P(t \\geq a) \\leq \\frac{E(t)}{a}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) 利用a的结果, 令 $$x = u-\\mu, t= x^2>=0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "则: $$P(t \\geq a) \\leq \\frac{E(t)}{a}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$E(t) = E[(u-\\mu)^2] = \\sigma^2$$\n",
    "\n",
    "so, \n",
    "\n",
    "$$P(t \\geq a) \\leq \\frac{\\sigma^2}{a}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) 随机变量 $$u_1, u_2, ..., u_N$$ 均值和方差 分别为$$\\mu, \\sigma^2$$\n",
    "\n",
    "若他们相互独立, 则 $$u_1 + u_2 + ... + u_N$$ 的均值和方差分别为 $$N\\mu, N\\sigma^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "变量 $$u = \\frac{1}{N} \\sum_{n=1}^{N}u_n$$ d的均值和方差分别为:$$\\mu, \\frac{\\sigma^2}{N}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "利用(a)(b)的结果, 可以得到:\n",
    "\n",
    "$$\\Bbb P [(u-\\mu)^2 \\geq a] \\leq \\frac{\\sigma^2/N}{a} = \\frac{\\sigma^2}{Na}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prob 1.9\n",
    "\n",
    "(a). 利用 Prob1.8 (a)的结论, t 是(有限的)随机变量, a 是正的常数, s为正的参数\n",
    "\n",
    "$$e^{st}$$肯定为正的随机变量, $$e^{sa}>0$$\n",
    "\n",
    "$$\\Bbb P[e^{st} \\geq e^{sa}] \\leq \\frac{\\Bbb{E_t}(e^st)}{e^{sa}} \\Rightarrow\n",
    "\\Bbb P[t \\geq a] \\leq \\frac{\\Bbb{E_t}(e^st)}{e^{sa}}=e^{-sa}T(s)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b). $$\\begin{align}\n",
    "\\Bbb P [u \\geq a] &= \\Bbb P[\\frac{1}{N}\\sum_{n}u_n \\geq a] \\\\\n",
    " &= \\Bbb P[\\sum_{n}u_n \\geq Na] \\\\\n",
    " &= \\Bbb P[e^{s\\sum_{n}u_n} \\geq e^{sNa}] \\\\\n",
    " &\\leq \\frac{\\Bbb E(e^{s\\sum_n{u_n}})}{e^{sNa}} & Markov \\ inequality(conditions \\ are \\ ok)\\\\\n",
    " &= \\frac{\\Bbb E(\\prod_n e^{su_n})}{e^{sNa}} \\\\\n",
    " &= \\frac{\\prod_n {\\Bbb E(e^{u_n})}}{e^{sNa}} \\\\\n",
    " &= (e^{-sa}U(s))^N\n",
    "     \\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c).$$P[u_n=0] = P[u_n=1] = 0.5$$\n",
    "\n",
    "then $$P[e^{s u_n} = 1] = P[e^{s u_n} = e^s] = 0.5$$\n",
    "\n",
    "then, $$U(S) = E_{u_n}[e^{s u_n}] = 0.5*1 + 0.5*e^s = \\frac{1}{2}(1+e^s)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "利用 b 的结论, \n",
    "\n",
    "$$P[u_n \\geq a] \\leq e^{-sa} U(s)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因为: $$0 < a < 1$$ \n",
    "\n",
    "$$P[u_n \\geq a] = P[u_n = 1] = \\frac{1}{2} \\leq e^{-sa}U(s)$$\n",
    "\n",
    "所以 $$ \\min {e^{-sa}U(s)} = \\frac{1}{2}$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{align}\n",
    "e^{-sa}U(s) &= \\frac{1}{2}(e^{-sa}+e^{(1-a)s}) \n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) I can't fix it. then 放着再说"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Prob 1.10\n",
    "\n",
    "**a)** M为偶数的情况: $$E_off = 0.5$$\n",
    "\n",
    "M为奇数, N为偶数: $$E_off = \\frac{1}{M}(\\frac{M-1}{2} + 1) = 0.5 + \\frac{1}{M}$$\n",
    "\n",
    "M为奇数, N为奇数: $$E_off = \\frac{1}{M} \\frac{M-1}{2} = \\frac{1}{2} - \\frac{1}{M}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b**, 只要从输入样本空间 X 中能得出 N个 y_n = f(x_n) 即可\n",
    "\n",
    "$$\\binom {N+M} N$$, 有这么多种情况, 但是f的情况, 就可以无限多. 只要能保证 N个 训练样本无噪声即可.(y_n = f(x_n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c** 对于上面的 f, 能产生多少个 f 满足 $$E_{off}(h-f) = \\frac{k}{M}$$?\n",
    "\n",
    "在b的基础上, 产生的f可使得M中有k个出现错误, 即 $$\\binom M k$$, 但至于f如何确定, who konws? I don't care. Just thinking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d** 所有 f 产生无噪声数据的概率相同, 即使如此, 我也不知道该如何求均值. \n",
    "\n",
    "**e** 未解."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prob 1.11\n",
    "\n",
    "对于不同的error 施加不同的权重. \n",
    "\n",
    "$$E_{in} = \\sum_{i}^{n} w_i \\cdot sign(h(x_i) - f(x_i))$$\n",
    "\n",
    "$$\\begin{cases} \n",
    "sign(h(x_i) - f(x_i) = 0, w_i = 0 \\\\\n",
    "sign(h(x_i) - f(x_i) = -1, w_i \\\\\n",
    "sign(h(x_i) - f(x_i) = 1, w_i\n",
    "\\end{cases}$$\n",
    "\n",
    "在$$sign(h(x_i) - f(x_i) = -1 \\ or \\ +1 $$的情况, 根据情景确定权重值."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prob 1.12\n",
    "\n",
    "**a** \n",
    "\n",
    "$$\\begin{align}\n",
    "E_{in}(h) &= \\sum_{n=1}^{N}(h-y_n)^2 \\\\\n",
    "          &= Nh^2 - 2h\\sum_{n=1}^{N}y_n + \\sum_{n=1}^{N}y_n^2 \n",
    "\\end{align}$$\n",
    "\n",
    "E_in 小, 求导为0, 得到 h. \n",
    "\n",
    "$$E_{in}' = 2Nh - 2\\sum_{n=1}^{N}y_n \\Rightarrow h = \\frac{1}{N}\\sum_{n=1}^{N}y_n$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b**: 直观上看, 是中位数.\n",
    "\n",
    "那么还是得证明:\n",
    "\n",
    "$$E_in(h)= \\sum_{n=1}{N} \\mid h - y_n \\mid$$\n",
    "\n",
    "因为 $$y_1 < y_2 < ... < y_N$$ 存在一个k为大于 h 的临界点 \n",
    "$$E_{in}(h) = \\sum_{n=1}^{k}(h-y_n) + \\sum_{n=k+1}^{N}(y_n-h)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对h求导: \n",
    "\n",
    "$$E_{in}(h)' = \\sum_{n=1}^{k}(1) + \\sum_{n=k}^{N}(-1) =0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以得到: k = N-k + 1\n",
    "\n",
    "$$k = \\frac{N+1}{2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "那么 $$h_{med}=y_{k}$$ 为它们的中位数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c**\n",
    "\n",
    "$$h_{mean}$$ 也会变得非常大.\n",
    "\n",
    "$$h_{med}$$ 则不变化, 中位数的确定不依赖与 $$y_N$$, 而依赖于中间两个数(或一个数)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
